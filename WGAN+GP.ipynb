{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOG75GRuF3WoAV9kPp0cjjw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hnqmz/machine_learning/blob/master/WGAN%2BGP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W28icim4tY2"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from numpy.random import default_rng\n",
        "\n",
        "np.random.seed(42)\n",
        "rg=default_rng"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTc4kF0440oy",
        "outputId": "05e2f240-29e3-4a5d-cda3-548a0232fea1"
      },
      "source": [
        "IMG_SHAPE=(28, 28, 1)\n",
        "BATCH_SIZE=512\n",
        "\n",
        "noise_dim=128\n",
        "\n",
        "fashion_mnist=tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_tr, y_tr), (x_te, y_te)=fashion_mnist.load_data()\n",
        "print('Number of examples: %s' % (len(x_tr)))\n",
        "print('Shape of examples (%s, %s)' % (x_tr.shape[1], x_tr.shape[2]))\n",
        "\n",
        "x_tr=x_tr.reshape((-1, 28, 28, 1)).astype('float32')\n",
        "x_tr=(x_tr-127.5)/127.5\n",
        "#from sklearn.preprocessing import standart_scaler"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Number of examples: 60000\n",
            "Shape of examples (28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W_fIyhB420T"
      },
      "source": [
        "def conv_block(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    padding='same',\n",
        "    use_bias=True,\n",
        "    use_bn=False,\n",
        "    use_dropout=False,\n",
        "    drop_value=0.5,):\n",
        "\n",
        "    x=layers.Conv2D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias)(x)\n",
        "    if use_bn:\n",
        "        x=layers.BatchNormalization()(x)\n",
        "    x=activation(x)\n",
        "    if use_dropout:\n",
        "        x=layers.Dropout(drop_value)(x)\n",
        "    return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmIYptyO48LT",
        "outputId": "12a11667-8973-41dc-eecb-309dc7a3bf51"
      },
      "source": [
        "def get_d_model():\n",
        "    img_input=layers.Input(shape=IMG_SHAPE)\n",
        "    x=layers.ZeroPadding2D((2, 2))(img_input)\n",
        "    x=conv_block(\n",
        "        x,\n",
        "        64,\n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        use_bias=True,\n",
        "        activation=layers.LeakyReLU(alpha=0.2),\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3\n",
        "    ) \n",
        "    x=conv_block(\n",
        "        x,\n",
        "        128,\n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=True,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x=conv_block(\n",
        "        x, \n",
        "        256, \n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        activation=tf.keras.layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=True,\n",
        "        drop_value=0.3,\n",
        "\n",
        "    )\n",
        "    x=conv_block(\n",
        "        x,\n",
        "        512,\n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        use_bias=True,\n",
        "        activation=tf.keras.layers.LeakyReLU(0.2),\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "\n",
        "    x=layers.Flatten()(x)\n",
        "    x=layers.Dropout(0.2)(x)\n",
        "    x=layers.Dense(1)(x)\n",
        "\n",
        "    d_model=tf.keras.Model(img_input, x, name='d_model')\n",
        "    return d_model\n",
        "\n",
        "d_model=get_d_model()\n",
        "d_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"d_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2 (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 16, 16, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 512)         3277312   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 4,305,409\n",
            "Trainable params: 4,305,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfaAUZgb5Aky",
        "outputId": "8a668eb8-bbe2-4234-d911-0b8de6a1de70"
      },
      "source": [
        "def upsample_block(\n",
        "    x, \n",
        "    filters, \n",
        "    activation, \n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    \n",
        "    padding='same',\n",
        "    use_bn=False, \n",
        "    use_bias=True,\n",
        "    use_dropout=False,\n",
        "    drop_value=0.3):\n",
        "\n",
        "    x=layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias)(x)\n",
        "    \n",
        "    if use_bn:\n",
        "        x=layers.BatchNormalization()(x)\n",
        "    if activation:\n",
        "        x=activation(x)\n",
        "    if use_dropout:\n",
        "        x=layers.Dropout(drop_value)(x)\n",
        "    return x\n",
        "\n",
        "def get_g_model():\n",
        "    noise=layers.Input(shape=(noise_dim, ))\n",
        "    x=layers.Dense(4*4*256, use_bias=False)(noise)\n",
        "    x=layers.BatchNormalization()(x)\n",
        "    x=layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x=layers.Reshape((4, 4, 256))(x)\n",
        "    x=upsample_block(\n",
        "        x, \n",
        "        128, \n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=(2, 2),\n",
        "        use_bias=False,\n",
        "        use_bn=True, \n",
        "        use_dropout=False,\n",
        "    )\n",
        "    x=upsample_block(\n",
        "        x, \n",
        "        64, \n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=(2, 2),\n",
        "        use_bias=False,\n",
        "        use_bn=True,\n",
        "        use_dropout=False,\n",
        "\n",
        "    )\n",
        "    x=upsample_block(\n",
        "        x, 1, layers.Activation('tanh'), strides=(2, 2), use_bias=False, use_bn=True\n",
        "    )\n",
        "    x=layers.Cropping2D((2, 2))(x)\n",
        "\n",
        "    g_model=tf.keras.Model(noise, x, name='g_model')\n",
        "    return g_model\n",
        "\n",
        "g_model=get_g_model()\n",
        "g_model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"g_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 128)]             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              524288    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 8, 8, 128)         294912    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 64)        73728     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 1)         576       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 1)         4         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "cropping2d (Cropping2D)      (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 910,660\n",
            "Trainable params: 902,082\n",
            "Non-trainable params: 8,578\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DqSjCeU5Em9"
      },
      "source": [
        "class WGAN(tf.keras.Model):\n",
        "    def __init__(self, d_model, g_model, latent_dim, d_extra_steps=3, gp_weight=10.0):\n",
        "        super().__init__()\n",
        "        self.d_model=d_model\n",
        "        self.g_model=g_model\n",
        "        self.latent_dim=latent_dim\n",
        "        self.d_steps=d_extra_steps\n",
        "        self.gp_weight=gp_weight\n",
        "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer=d_optimizer\n",
        "        self.g_optimizer=g_optimizer\n",
        "        self.d_loss_fn=d_loss_fn\n",
        "        self.g_loss_fn=g_loss_fn\n",
        "    def gp(self, batch_size, real_images, fake_images):\n",
        "        alpha=tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
        "        diff=fake_images-real_images\n",
        "        interpolated=real_images+alpha*diff \n",
        "\n",
        "        with tf.GradientTape() as gp_tape:\n",
        "            gp_tape.watch(interpolated)\n",
        "            pred=self.d_model(interpolated, training=True)\n",
        "        grads=gp_tape.gradient(pred, [interpolated])[0]\n",
        "        norm=tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
        "        gpn=tf.reduce_mean((norm-1.0)**2)\n",
        "        return gpn \n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images=real_images[0]\n",
        "        batch_size=tf.shape(real_images)[0]\n",
        "\n",
        "        for i in range(self.d_steps):\n",
        "            random_latent_vectors=tf.random.normal(\n",
        "                shape=(batch_size, self.latent_dim)\n",
        "            )\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                fake_img=self.g_model(random_latent_vectors, training=True)\n",
        "                fake_logits=self.d_model(fake_img, training=True)\n",
        "                real_logits=self.d_model(real_images, training=True)\n",
        "\n",
        "                d_cost=self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
        "                gp=self.gp(batch_size, real_images, fake_img)\n",
        "\n",
        "                d_loss=d_cost+self.gp_weight*gp\n",
        "\n",
        "            d_gradient=tape.gradient(d_loss, self.d_model.trainable_variables)\n",
        "            self.d_optimizer.apply_gradients(\n",
        "                zip(d_gradient, self.d_model.trainable_variables)\n",
        "\n",
        "            )\n",
        "\n",
        "        random_latent_vectors=tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_img=self.g_model(random_latent_vectors, training=True)\n",
        "            gen_img_logits=self.d_model(generated_img, training=True)\n",
        "            g_loss=self.g_loss_fn(gen_img_logits)\n",
        "\n",
        "        gen_gradient=tape.gradient(g_loss, self.g_model.trainable_variables)\n",
        "\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(gen_gradient, self.g_model.trainable_variables)\n",
        "        )\n",
        "\n",
        "        return {'d_loss': d_loss, 'g_loss':g_loss}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVjxiNqI5KP9"
      },
      "source": [
        "class GANMonitor(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=6, latent_dim=128):\n",
        "        self.num_img=num_img\n",
        "        self.latent_dim=latent_dim\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors=tf.random.normal((self.num_img, self.latent_dim))\n",
        "        generated_img=self.model.g_model(random_latent_vectors)\n",
        "        generated_img=(generated_img*127.5)+127.5\n",
        "\n",
        "        for i in range(self.num_img):\n",
        "            img=generated_img[i].numpy()\n",
        "            img=tf.keras.preprocessing.image.array_to_img(img)\n",
        "            img.save('generated_img_{i}_{epoch}.png'.format(i=i, epoch=epoch))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vcZaxwX5M8r",
        "outputId": "7f9316dc-a3ce-4f5c-8caa-2a310059c67e"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
        ")\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
        ")\n",
        "\n",
        "# Define the loss functions for the discriminator,\n",
        "# which should be (fake_loss - real_loss).\n",
        "# We will add the gradient penalty later to this loss function.\n",
        "def discriminator_loss(real_img, fake_img):\n",
        "    real_loss = tf.reduce_mean(real_img)\n",
        "    fake_loss = tf.reduce_mean(fake_img)\n",
        "    return fake_loss - real_loss\n",
        "\n",
        "\n",
        "# Define the loss functions for the generator.\n",
        "def generator_loss(fake_img):\n",
        "    return -tf.reduce_mean(fake_img)\n",
        "\n",
        "\n",
        "# Set the number of epochs for trainining.\n",
        "epochs = 20\n",
        "\n",
        "# Instantiate the customer `GANMonitor` Keras callback.\n",
        "cbk = GANMonitor(num_img=3, latent_dim=noise_dim)\n",
        "\n",
        "# Instantiate the WGAN model.\n",
        "wgan = WGAN(\n",
        "    d_model=d_model,\n",
        "    g_model=g_model,\n",
        "    latent_dim=noise_dim,\n",
        "    d_extra_steps=3,\n",
        ")\n",
        "\n",
        "# Compile the WGAN model.\n",
        "wgan.compile(\n",
        "    d_optimizer=discriminator_optimizer,\n",
        "    g_optimizer=generator_optimizer,\n",
        "    g_loss_fn=generator_loss,\n",
        "    d_loss_fn=discriminator_loss,\n",
        ")\n",
        "\n",
        "# Start training the model.\n",
        "wgan.fit(x_tr, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "118/118 [==============================] - 168s 1s/step - d_loss: -12.9065 - g_loss: -9.3999\n",
            "Epoch 2/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -8.9641 - g_loss: 1.1074\n",
            "Epoch 3/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -8.2628 - g_loss: 12.7697\n",
            "Epoch 4/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -7.3365 - g_loss: 18.8487\n",
            "Epoch 5/20\n",
            "118/118 [==============================] - 132s 1s/step - d_loss: -6.5150 - g_loss: 26.6912\n",
            "Epoch 6/20\n",
            "118/118 [==============================] - 132s 1s/step - d_loss: -5.8440 - g_loss: 26.6328\n",
            "Epoch 7/20\n",
            "118/118 [==============================] - 132s 1s/step - d_loss: -5.3622 - g_loss: 25.9911\n",
            "Epoch 8/20\n",
            "118/118 [==============================] - 132s 1s/step - d_loss: -4.9319 - g_loss: 23.9385\n",
            "Epoch 9/20\n",
            "118/118 [==============================] - 132s 1s/step - d_loss: -4.6166 - g_loss: 21.8118\n",
            "Epoch 10/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -4.2912 - g_loss: 19.6547\n",
            "Epoch 11/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -4.0495 - g_loss: 18.4871\n",
            "Epoch 12/20\n",
            "118/118 [==============================] - 132s 1s/step - d_loss: -3.8528 - g_loss: 17.0170\n",
            "Epoch 13/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -3.6374 - g_loss: 15.3792\n",
            "Epoch 14/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -3.5195 - g_loss: 13.9538\n",
            "Epoch 15/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -3.3510 - g_loss: 12.1598\n",
            "Epoch 16/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -3.2192 - g_loss: 11.4137\n",
            "Epoch 17/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -3.0819 - g_loss: 11.3263\n",
            "Epoch 18/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -2.9834 - g_loss: 11.7820\n",
            "Epoch 19/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -2.8822 - g_loss: 10.8847\n",
            "Epoch 20/20\n",
            "118/118 [==============================] - 133s 1s/step - d_loss: -2.7635 - g_loss: 10.0774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe2f47b1690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "843SDec8D8V0",
        "outputId": "65997900-483b-4ff2-9b86-5916042d1f11"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "plt.figure(figsize=(3, 9))\n",
        "for i in range(3):\n",
        "  im=Image.open('generated_img_{}_19.png'.format(i))\n",
        "  im=np.asarray(im)\n",
        "  plt.subplot(1, 3, i+1)\n",
        "  plt.imshow(im, cmap='gray_r')\n",
        "  plt.axis('off')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x648 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt-djZhzEfHY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}